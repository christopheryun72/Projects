{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KbWv0EOhxJpj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import requests\n",
    "import csv\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PGSPOlvjxJpo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffSentence', ' 1 September 23, 1932, the Secretary of Agriculture, acting under the Packers and Stockyards Act, 1921,1 ordered an inquiry and gave notice of a hearing to determine the reasonableness of rates charged by market agencies doing business at the Union Stockyards in Chicago', ' After protracted hearings and argument, he made findings of fact, announced his conclusion that the existing rates were unreasonable, and fixed new maximum rates', ' The appellants, who conduct market agencies, petitioned for rehearing', ' This the secretary denied, but by a supplemental order he increased some rates', ' An amended petition for rehearing was dismissed and the appellants then filed their bill in the District Court seeking an injunction against enforcement of the original and supplemental orders', ' The case was heard by three judges, who granted an interlocutory injunction', \" At final hearing, the appellants offered in evidence the record of the proceedings before the secretary and also proffered additional testimony which was received over the appellees' objection and subject to their exception\", \" The court dismissed the bill, holding that the secretary's findings were supported by substantial evidence\", \" In the light of the evidence before him, and that adduced at the trial, the court adopted the secretary's findings as its own; adjudged the prescribed rates reasonable, and concluded the orders entered were not arbitrary and did not operate so as to take the agencies' property without due process of law\"]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "with open('judgesSentencesOnly.csv', newline='') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for row in reader:\n",
    "        sentences.append(row)\n",
    "sents = [sent[0] for sent in sentences if len(sent[0]) > 2]\n",
    "print(sents[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "scrW5T6sxJpq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffSentence  1 September 23, 193'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = \" \".join(sents)\n",
    "sents[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RVTVuRUJxJpt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['september',\n",
       " 'the',\n",
       " 'secretary',\n",
       " 'of',\n",
       " 'agriculture',\n",
       " 'acting',\n",
       " 'under',\n",
       " 'the',\n",
       " 'packers',\n",
       " 'and']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(data):\n",
    "  words = data.split()\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  words = [word.translate(table) for word in words]\n",
    "  words = [word for word in words if word.isalpha() ]\n",
    "  words = [word.lower() for word in words]\n",
    "  return words\n",
    "\n",
    "cleanSents = clean_text(sents)\n",
    "cleanSents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NemG6ZfSxJpv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'september the secretary of agriculture acting under the packers and stockyards act ordered an inquiry'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predLength = 15\n",
    "groups = []\n",
    "for i in range(predLength, len(cleanSents)):\n",
    "    part = cleanSents[i - predLength: i]\n",
    "    grouping = ' '.join(part)\n",
    "    groups.append(grouping)\n",
    "print(len(groups))\n",
    "groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0mski0DrxJpy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(groups)\n",
    "sequences = tokenizer.texts_to_sequences(groups)\n",
    "print(type(sequences))\n",
    "sequences = np.array(sequences)\n",
    "print(type(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Tpq9zbJoxJp0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81522, 15)\n",
      "[ 663    1  123    2 1186 2739   48    1 5652    4 2738   22  579   24]\n",
      "1657\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(sequences))\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Qo42ZGvIxJp2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWords = 1 + len(tokenizer.word_index)\n",
    "uniqueWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "G7Sth0EfxJp6"
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_rBjpAN0xJp7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 14, 14)            79142     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 14, 256)           277504    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5653)              1452821   \n",
      "=================================================================\n",
      "Total params: 2,466,363\n",
      "Trainable params: 2,466,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnnModel = tf.keras.models.Sequential()\n",
    "rnnModel.add(tf.keras.layers.Embedding(uniqueWords, 14, input_length=14))\n",
    "rnnModel.add(tf.keras.layers.LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n",
    "rnnModel.add(tf.keras.layers.LSTM(256, return_sequences=False, dropout=0.3, recurrent_dropout=0.2))\n",
    "rnnModel.add(tf.keras.layers.Dense(units = 256, activation='relu'))\n",
    "rnnModel.add(tf.keras.layers.Dense(units = 256, activation='relu'))\n",
    "rnnModel.add(tf.keras.layers.Dense(units = uniqueWords, activation='softmax'))\n",
    "rnnModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AWV3-2nlxJp9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81522, 14)\n",
      "(81522, 5653)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "p1Guhq_lxJp_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1274/1274 [==============================] - 150s 118ms/step - loss: 6.2524 - accuracy: 0.1178\n",
      "Epoch 2/50\n",
      "1274/1274 [==============================] - 158s 124ms/step - loss: 5.7961 - accuracy: 0.1449\n",
      "Epoch 3/50\n",
      "1274/1274 [==============================] - 157s 123ms/step - loss: 5.5798 - accuracy: 0.1534\n",
      "Epoch 4/50\n",
      "1274/1274 [==============================] - 165s 130ms/step - loss: 5.4417 - accuracy: 0.1628\n",
      "Epoch 5/50\n",
      "1274/1274 [==============================] - 163s 128ms/step - loss: 5.3124 - accuracy: 0.1726\n",
      "Epoch 6/50\n",
      "1274/1274 [==============================] - 152s 119ms/step - loss: 5.1948 - accuracy: 0.1811\n",
      "Epoch 7/50\n",
      "1274/1274 [==============================] - 160s 125ms/step - loss: 5.0943 - accuracy: 0.1886\n",
      "Epoch 8/50\n",
      "1274/1274 [==============================] - 161s 126ms/step - loss: 4.9993 - accuracy: 0.1943\n",
      "Epoch 9/50\n",
      "1274/1274 [==============================] - 162s 127ms/step - loss: 4.9097 - accuracy: 0.1970\n",
      "Epoch 10/50\n",
      "1274/1274 [==============================] - 161s 126ms/step - loss: 4.8264 - accuracy: 0.2000\n",
      "Epoch 11/50\n",
      "1274/1274 [==============================] - 154s 121ms/step - loss: 4.7484 - accuracy: 0.2027\n",
      "Epoch 12/50\n",
      "1274/1274 [==============================] - 157s 123ms/step - loss: 4.6732 - accuracy: 0.2054\n",
      "Epoch 13/50\n",
      "1274/1274 [==============================] - 162s 127ms/step - loss: 4.6052 - accuracy: 0.2081\n",
      "Epoch 14/50\n",
      "1274/1274 [==============================] - 157s 123ms/step - loss: 4.5429 - accuracy: 0.2088\n",
      "Epoch 15/50\n",
      "1274/1274 [==============================] - 160s 125ms/step - loss: 4.4792 - accuracy: 0.2109\n",
      "Epoch 16/50\n",
      "1274/1274 [==============================] - 160s 126ms/step - loss: 4.4238 - accuracy: 0.2120\n",
      "Epoch 17/50\n",
      "1274/1274 [==============================] - 160s 126ms/step - loss: 4.3607 - accuracy: 0.2146\n",
      "Epoch 18/50\n",
      "1274/1274 [==============================] - 161s 127ms/step - loss: 4.3074 - accuracy: 0.2161\n",
      "Epoch 19/50\n",
      "1274/1274 [==============================] - 160s 126ms/step - loss: 4.2546 - accuracy: 0.2176\n",
      "Epoch 20/50\n",
      "1274/1274 [==============================] - 158s 124ms/step - loss: 4.2009 - accuracy: 0.2191\n",
      "Epoch 21/50\n",
      "1274/1274 [==============================] - 163s 128ms/step - loss: 4.1549 - accuracy: 0.2219\n",
      "Epoch 22/50\n",
      "1274/1274 [==============================] - 163s 128ms/step - loss: 4.1102 - accuracy: 0.2238\n",
      "Epoch 23/50\n",
      "1274/1274 [==============================] - 162s 127ms/step - loss: 4.0631 - accuracy: 0.2257\n",
      "Epoch 24/50\n",
      "1274/1274 [==============================] - 164s 129ms/step - loss: 4.0210 - accuracy: 0.2282\n",
      "Epoch 25/50\n",
      "1274/1274 [==============================] - 163s 128ms/step - loss: 3.9783 - accuracy: 0.2298\n",
      "Epoch 26/50\n",
      "1274/1274 [==============================] - 159s 125ms/step - loss: 3.9382 - accuracy: 0.2333\n",
      "Epoch 27/50\n",
      "1274/1274 [==============================] - 167s 131ms/step - loss: 3.8995 - accuracy: 0.2332\n",
      "Epoch 28/50\n",
      "1274/1274 [==============================] - 162s 127ms/step - loss: 3.8673 - accuracy: 0.2368\n",
      "Epoch 29/50\n",
      "1274/1274 [==============================] - 163s 128ms/step - loss: 3.8265 - accuracy: 0.2409\n",
      "Epoch 30/50\n",
      "1274/1274 [==============================] - 161s 127ms/step - loss: 3.7922 - accuracy: 0.2423\n",
      "Epoch 31/50\n",
      "1274/1274 [==============================] - 163s 128ms/step - loss: 3.7591 - accuracy: 0.2440\n",
      "Epoch 32/50\n",
      "1274/1274 [==============================] - 162s 127ms/step - loss: 3.7248 - accuracy: 0.2463\n",
      "Epoch 33/50\n",
      "1274/1274 [==============================] - 156s 122ms/step - loss: 3.6890 - accuracy: 0.2508\n",
      "Epoch 34/50\n",
      "1274/1274 [==============================] - 159s 125ms/step - loss: 3.6605 - accuracy: 0.2504\n",
      "Epoch 35/50\n",
      "1274/1274 [==============================] - 158s 124ms/step - loss: 3.6293 - accuracy: 0.2561\n",
      "Epoch 36/50\n",
      "1274/1274 [==============================] - 156s 123ms/step - loss: 3.5983 - accuracy: 0.2581\n",
      "Epoch 37/50\n",
      "1274/1274 [==============================] - 164s 129ms/step - loss: 3.5663 - accuracy: 0.2615\n",
      "Epoch 38/50\n",
      "1274/1274 [==============================] - 162s 127ms/step - loss: 3.5387 - accuracy: 0.2638\n",
      "Epoch 39/50\n",
      "1274/1274 [==============================] - 165s 130ms/step - loss: 3.5054 - accuracy: 0.2680\n",
      "Epoch 40/50\n",
      "1274/1274 [==============================] - 161s 126ms/step - loss: 3.4786 - accuracy: 0.2697\n",
      "Epoch 41/50\n",
      "1274/1274 [==============================] - 160s 125ms/step - loss: 3.4577 - accuracy: 0.2721\n",
      "Epoch 42/50\n",
      "1274/1274 [==============================] - 160s 125ms/step - loss: 3.4261 - accuracy: 0.2752\n",
      "Epoch 43/50\n",
      "1274/1274 [==============================] - 161s 126ms/step - loss: 3.4009 - accuracy: 0.2783\n",
      "Epoch 44/50\n",
      "1274/1274 [==============================] - 150s 118ms/step - loss: 3.3710 - accuracy: 0.2821\n",
      "Epoch 45/50\n",
      "1274/1274 [==============================] - 150s 118ms/step - loss: 3.3516 - accuracy: 0.2839\n",
      "Epoch 46/50\n",
      "1274/1274 [==============================] - 149s 117ms/step - loss: 3.3304 - accuracy: 0.2868\n",
      "Epoch 47/50\n",
      "1274/1274 [==============================] - 150s 117ms/step - loss: 3.3006 - accuracy: 0.2913\n",
      "Epoch 48/50\n",
      "1274/1274 [==============================] - 170s 134ms/step - loss: 3.2844 - accuracy: 0.2920\n",
      "Epoch 49/50\n",
      "1274/1274 [==============================] - 177s 139ms/step - loss: 3.2591 - accuracy: 0.2944\n",
      "Epoch 50/50\n",
      "1274/1274 [==============================] - 189s 148ms/step - loss: 3.2399 - accuracy: 0.2972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe820f467d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
    "rnnModel.fit(X, y, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wJ1R1l69xJqB"
   },
   "outputs": [],
   "source": [
    "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, numWords):\n",
    "  predText = []\n",
    "  for _ in range(numWords):\n",
    "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    encoded = pad_sequences([encoded], maxlen=text_seq_length, truncating='pre')\n",
    "    y_pred = model.predict_classes(encoded)\n",
    "    predWord = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == y_pred:\n",
    "        predWord = word\n",
    "        break\n",
    "    seed_text = seed_text + ' ' + predWord\n",
    "    predText.append(predWord)\n",
    "  return ' '.join(predText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tw0QkasixJqC"
   },
   "outputs": [],
   "source": [
    "seed_text = groups[200]\n",
    "#generate_text_seq(rnnModel, tokenizer, 14, seed_text, 15)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "RealRNNTextGeneration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
